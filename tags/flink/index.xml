<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Flink on Hashim Colombowala</title><link>https://hashimcolombowala.com/tags/flink/</link><description>Recent content in Flink on Hashim Colombowala</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 07 Oct 2024 23:00:00 -0700</lastBuildDate><atom:link href="https://hashimcolombowala.com/tags/flink/index.xml" rel="self" type="application/rss+xml"/><item><title>What is flink and why should we care about it</title><link>https://hashimcolombowala.com/p/flink/</link><pubDate>Mon, 07 Oct 2024 23:00:00 -0700</pubDate><guid>https://hashimcolombowala.com/p/flink/</guid><description>&lt;img src="https://hashimcolombowala.com/p/flink/cover.jpg" alt="Featured image of post What is flink and why should we care about it" />&lt;p>Recently, the observability team was tasked with a latency reporting project. The key features included:&lt;/p>
&lt;ul>
&lt;li>Daily and monthly latency aggregations&lt;/li>
&lt;li>Support for various quantiles&lt;/li>
&lt;li>A reasonable data delay SLO (24 hours)&lt;/li>
&lt;/ul>
&lt;p>and more. For the purpose of this blog, we will focus on the data processing aspect. We needed a system that could read latency data from a Kafka stream, partition the data by various attributes such as endpoints, and precompute hourly, daily, and weekly quantiles (e.g., p50, p99).&lt;/p>
&lt;h2 id="why-did-we-choose-flink">Why did we choose Flink?
&lt;/h2>&lt;p>We chose Flink because of several key features:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Stateful processing&lt;/strong>: It allows us to maintain state across events.&lt;/li>
&lt;li>&lt;strong>Built-in windowing support&lt;/strong>: Flink offers windowing functions (e.g., tumbling, sliding) that divide the data stream into finite subsets (windows) based on time or count.&lt;/li>
&lt;li>&lt;strong>Scalability&lt;/strong>: It can handle high-throughput data streams, such as those from Kafka.&lt;/li>
&lt;li>&lt;strong>Fault tolerance&lt;/strong>: Through state snapshots and checkpointing, Flink ensures resilience.&lt;/li>
&lt;/ul>
&lt;h2 id="flink-playground">Flink Playground
&lt;/h2>&lt;p>Naturally, besides going through the flink documentation [insert link], I decided go to my usual playground of choice. Docker. Below is the architecture. Checkout the &lt;a class="link" href="https://github.com/hash167/flink_kafka_playground/blob/1dc2292f4ce0fa64fc3a41803c06ff5008955d11/README.md" target="_blank" rel="noopener"
>code&lt;/a> and &lt;a class="link" href="https://github.com/hash167/flink_kafka_playground/blob/1dc2292f4ce0fa64fc3a41803c06ff5008955d11/docker-compose.yml#L1" target="_blank" rel="noopener"
>docker-compose.yml&lt;/a> for more information. Below is the basic architecture.&lt;/p>
&lt;script type="module">
import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
mermaid.initialize({ startOnLoad: true });
&lt;/script>
&lt;div class="mermaid">
graph TD;
P["Python App (produces latency data)"] --> A["Kafka Broker (latency topic)"]
%% Python app produces random latency data and sends it to the Kafka broker
A --> B["Flink Pipeline"]
%% Kafka Broker receives latency messages produced by the Python app, which are consumed by the Flink pipeline for processing
B --> C["1-Minute Tumbling Window"]
%% The Flink Pipeline splits the data stream into a 1-minute tumbling window for short-term aggregation
B --> D["1-Hour Tumbling Window"]
%% The Flink Pipeline also splits the data stream into a 1-hour tumbling window for long-term aggregation
C --> E["P50/P99 Aggregation"]
%% Once the 1-minute window is over, the data is processed to calculate P50 and P99 latency metrics
D --> F["P50/P99 Aggregation"]
%% Once the 1-hour window is over, the data is also processed to calculate P50 and P99 latency metrics
E --> G["Storage System (P50/P99 results)"]
%% The aggregated results from the 1-minute window are sent to a storage system for further use
F --> G["Storage System (P50/P99 results)"]
%% The aggregated results from the 1-hour window are also sent to a storage system for further use
&lt;/div>
&lt;h2 id="so-what-impressed-me">So what impressed me?
&lt;/h2>&lt;p>Flink&amp;rsquo;s brilliance lies in its ability to effortlessly handle the complexity of distributed stream processing with concise, expressive code. take this one line for example&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-kotlin" data-lang="kotlin">&lt;span class="line">&lt;span class="cl"> &lt;span class="k">val&lt;/span> &lt;span class="py">oneMinuteWindows&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="n">latencyStream&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">.&lt;/span>&lt;span class="n">keyBy&lt;/span>&lt;span class="p">({&lt;/span> &lt;span class="k">it&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">timestamp&lt;/span> &lt;span class="p">/&lt;/span> &lt;span class="m">60000&lt;/span> &lt;span class="p">},&lt;/span> &lt;span class="nc">TypeInformation&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">of&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">object&lt;/span> &lt;span class="err">: &lt;/span>&lt;span class="nc">TypeHint&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="n">Long&lt;/span>&lt;span class="p">&amp;gt;()&lt;/span> &lt;span class="p">{}))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">.&lt;/span>&lt;span class="n">window&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">TumblingProcessingTimeWindows&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">of&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">Time&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">minutes&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">1&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">.&lt;/span>&lt;span class="n">process&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">LatencyAggregateProcessFunction&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">.&lt;/span>&lt;span class="n">returns&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">TypeInformation&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">of&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">object&lt;/span> &lt;span class="err">: &lt;/span>&lt;span class="nc">TypeHint&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="n">AggregateResult&lt;/span>&lt;span class="p">&amp;gt;()&lt;/span> &lt;span class="p">{}))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Flink simplifies real-time data processing by abstracting away many low-level concerns while giving developers precise control over time, state, and computation. In this single line, Flink allows us to:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Partition the stream&lt;/strong>: The keyBy function logically partitions the incoming latencyStream based on timestamps, so each partition processes its events independently, enabling scalability in distributed environments.&lt;/li>
&lt;li>&lt;strong>Windowing&lt;/strong>: Using TumblingProcessingTimeWindows.of(Time.minutes(1)), Flink groups the data into 1-minute windows based on event processing time, making it easy to aggregate data over defined time intervals.&lt;/li>
&lt;li>&lt;strong>Custom processing&lt;/strong>: The process function applies a user-defined LatencyAggregateProcessFunction for calculating latency metrics, allowing custom logic to be executed for each window.&lt;/li>
&lt;li>&lt;strong>Type safety and efficiency&lt;/strong>: Using Flink’s TypeHint, we ensure type safety and help optimize serialization and deserialization in distributed environments, which enhances performance.&lt;/li>
&lt;/ol>
&lt;p>This one-liner hides a ton of complexity — from fault tolerance to scaling — and Flink’s ability to marry simplicity with powerful distributed processing is where it shines. In just a few lines of code, you have a resilient, scalable, and efficient stream processing pipeline!&lt;/p></description></item></channel></rss>