[{"content":"Background Imagine you\u0026rsquo;re writing a library to extend the prometheus python client and you needed to add some dynamic labels specific to the environment. Ideally you would add most of your labels at the collector end and avoid writing extensions.\nSay you need to inject some dynamic labels and you will need to at some point, we may want to extend the client.\nWhat are Generics? and why do we use them in python? Without sacrificing the inherent safety of a statically typed language, generic programming gives us primitives to declare “placeholder types” that allow us to focus less on the specific types that may be used or declared by other portions of the codebase, but rather focus on these higher-level patterns that can be consolidated into simpler declarations.\nPython has no built-in type checking. As long as a given Python program is syntactically valid, it will run, and issues like incompatible types will only surface at runtime. This forces the developer to ensure there is error handling in place to deal with such errors, and even with this, a common best practice is to use type hints combined with third-party linting tools to try to stay on top of issues like this.\nGenerics in my opinion is a programming stype for statically typed languages brought into python via type hints.\nSome code with comments from prometheus_client import Counter as _PromCounter from prometheus_client import Histogram as _PromHistogram from typing import TypeVar, Generics # a new generic type, bound to two types _MetricsTypeT = TypeVar('_MetricsTypeT', bound=[_PromCounter, _PromHistogram]) # base class of type generic(child class to pass type in) class _MetricsBase(Generic[_MetricsTypeT]): def __init__(self, label_names: Iterable[str]): self.default_labels: Dict[str] = get_default_labels() self.all_label_names: list = list(label_names) + list(self.default_labels.keys()) self._parent_metric: _MetricsTypeT = None # Provides the label functionality def labels(self, *labelargs, **labelkwargs) -\u0026gt; _MetricsTypeT: if labelargs: labelargs += tuple(self.default_labels.values()) return cast(_MetricsTypeT, self._parent_metric.labels(*labelargs)) labelkwargs.update(self.default_labels) return cast(_MetricsTypeT, self._parent_metric.labels(**labelkwargs)) # child class passing in type to base class via generics class Counter(_MetricsBase[_PromCounter]): def __init__(self, name, documentation, labelnames=()): super().__init__(label_names=labelnames) self._parent_metric = _PromCounter( name=name, documentation=documentation, labelnames=self.all_label_names) Complete code here\nThe final world In my project, I used generics programing to type my base class. My base clase _MetricsBase accepts a Generic type, passed in by classes(Counter, Histogram) inheritering from it. The common method label returns the generic type passed in from the child class. When we use third party linters like mypy, we get some of the controll of statically typed languages with python\n","description":"","id":0,"section":"posts","tags":["python","o11y"],"title":"Learning Generics by extending the prometheus python client","uri":"https://hashimcolombowala.com/posts/generics/"},{"content":"Requirements for metrics system  Multidimensional data model which can be sliced and diced along different dimensions as defined by the service(example: instance, service, endpoint, method) Operational simplicity Scalable data collection and decentralized architecture, so that independent teams can setup independent monitoring servers A powerful query language that leverages the data model for alerting and graphing  Client libraries  Client libraries take care of all the nitty gritty details like thread-safety, bookkeeping and producing the Prometheus text exposition format in response to HTTP request. As metrics-based monitoring does not track individual events, client library memory usage does not increase the more events you have. Rather, memory is related to the number of metrics you have.  Instrumentation There are 3 types of services\nOnline-serving systems: RED method, count of requests, errors and duration(latency). “synchronous function calls, and benefit from the same metrics of requests, latency, and errors. For a cache you would want these metrics both for the cache overall and the cache misses that then need to calculate the result or request it from a backend”\nOffline-serving systems: eg log processor. They usually batch up work, have multiple stages in a pipeline with queues between them. These systems run continuously which differentiates them from batch jobs. USE method.\nUtilization: How full your service is.how much work is in progress. How fast are you processing items\nSaturation: Amount of queued worked and how much work is in progress\nErrors: Self explanatory\nBatch jobs: How long it took to run, how long each stage took and the time at which the job last succeeded. Alerts for when the job hasn’t succeeded recently enough\nIdempotency for batch jobs: Idempotency is the property that if you do something more than once, it has the same result as if it was only done once.\n","description":"","id":1,"section":"posts","tags":["python","o11y"],"title":"Designing a metrics system notes","uri":"https://hashimcolombowala.com/posts/metrics/"},{"content":"This post will compare and contrast two most common authentication techniques breifly.\nSession Based Authentication In this scenario, the server will create a session for the user after the user logs in. The server creates a session id which is stored in memory or in an external cache for horizontal scaling. The client stores the session id in a cookie and sends the it in the request header for every subsequent request.\n1  Cookie: JSESSIONID=ABAD1D   The server can then verify the user by comparing the server id in the cookie against the session information stored in cache and responds accordingly.\nToken Authentication The server will generate a JWT(Json Web Token) with a secret and send it to the client. The client stores the JWT in a cookie or local brower memory. Subsequent requests made to server have the JWT in the header\n1  Authorization: Bearer eyJhbGciOiJIUzI1NiIXVCJ9TJV   The server validates the JWT to verify the user and respond accordingly.\nSession vs Token Tokens(JWT)\n Can work cross orgin across different domains. Downstream services can share tokens JWT based authentication scales well horizontally because tokens are stored on the client side Integrity protection by using a signature or MAC  Sessions\n More control over sessions as it is easier to invalidate. JWTs are valid till the expiration date is reached. If the JWT is encoded with a lot of data, it can slow down client requests. Session ids are just a string and very lightweight. Oauth2 solves this by having short lived access tokens and long lived refresh tokens  Conclusion In conclusion I would like to say that most production services can work with either models, so it depends on the use case. In fact many systems use a hybrid model with both types of authentication as well as combined model in which the JWT is associated with a user session for user tracking.\n","description":"","id":2,"section":"posts","tags":["python"],"title":"Authentication - Session or Token?","uri":"https://hashimcolombowala.com/posts/auth/"},{"content":"When deploying a containerized application to a container management system like AWS Fargate, you tend to run your application from a shell script. Suppose your script looks like this\n1 2 3  set -o nounset set -x gunicorn --config config/gunicorn/$GUNICORN_CONFIG.py config.wsgi   Here we are executing the gunicorn service with PID 1 when the container is deployed. Suppose we want to terminate the container with a docker stop \u0026lt;container_id\u0026gt;, the command will send a SIGTERM to the container. As the gunicorn process is PID 1, this signal is ignored.\nThe way to resolve this issue is to use exec before the command to start your application. The last line of the above shell script should be gunicorn --config config/gunicorn/$GUNICORN_CONFIG.py config.wsgi. A simple example is shown below\nt.py:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import signal import time got_signal = False def process_signal(signum, frame): global got_signal got_signal = True signal.signal(signal.SIGINT, process_signal) signal.signal(signal.SIGTERM, process_signal) while not got_signal: time.sleep(1) print(\u0026#34;looping...\u0026#34;) print(\u0026#34;Ended with signal.\u0026#34;)   entry.sh:\n1 2  #!/usr/bin/env bash exec python ./t.py   Dockerfile:\n1 2 3 4 5  FROMpython:3.7WORKDIR/usr/src/appCOPY . .CMD [ \u0026#34;./entry.sh\u0026#34; ]  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  With the exec: $ docker run --rm -t signal looping... looping... looping... looping... looping... looping... Ended with signal. $ Without the exec: $ docker run --rm -t signal looping... looping... looping... looping... looping... looping... $   Both times, you can run docker stop in another window. If the container doesn’t stop within 10 seconds, then it’s killed.\nMost apps do not explicitely handle SIGTERM the way t.py does. If you replace t.py with\n1 2 3 4 5 6 7  import time while True: time.sleep(1) print(\u0026#34;looping...\u0026#34;) print(\u0026#34;Ended with signal.\u0026#34;)   SIGINT will work with keyboard interrupt but docker stop does not because of PID=1 issue.\nIf we run docker with a --init option to force a non 1 PID, the docker stop works whether we use exec in the script or not.\nIn order to use this feature with AWS Fargate, make a small change to your AWS::ECS::TaskDefinition in your cloudformation as shown below\n1 2 3 4 5 6  ContainerDefinitions:- Name:\u0026lt;container_name\u0026gt;Image:\u0026lt;container_image\u0026gt;Essential:\u0026#34;true\u0026#34;linuxParameters:initProcessEnabled:\u0026#34;true\u0026#34;  ","description":"","id":3,"section":"posts","tags":["python","docker"],"title":"Signalling docker containers","uri":"https://hashimcolombowala.com/posts/signal/"},{"content":"In python3 all classes are new style classes, thus it is reasonable to refer to an objects type and its class interchangably\nType and Class 1 2 3 4 5 6 7  class Foo: pass \u0026gt;\u0026gt;\u0026gt; type(Foo) \u0026lt;class \u0026#39;type\u0026#39;\u0026gt;   Type is a metaclass of which classes are instances\n Foo is an instance of metaclass type type is an instance of type as well  Type Metaclass A type metaclass is initialized with 3 arguments\n name: name of the class (name attribute) bases: a tuple of classnames that the class inherits from namespace: a dictionary contianing definitions of the class body (dict attribute of the class)  Creating an abstract class manually with Metaclasses To understand metaclasses, we create an interface or abstract class implementation. Use from abc import ABC, abstractmethod when implementing something at work.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79  # test.py # Decorator to add attribute to function def abstract_func(func): func.__isabstract__ = True return func # This is the metaclass inheriting from `type` class Interface(type): def __init__(self, name, bases, namespace): print(f\u0026#34;Init method initialized from {self}\u0026#34;) class_methods = getattr(self, \u0026#39;all_methods\u0026#39;) for base in bases: required_methods = getattr(base, \u0026#39;abstract_methods\u0026#39;) for method in required_methods: if method not in class_methods: msg = f\u0026#34;\u0026#34;\u0026#34;Can\u0026#39;t create abstract class {name}! {name}must implement abstract method {method}of class {base}!\u0026#34;\u0026#34;\u0026#34; raise TypeError(msg) def __new__(cls, name, bases, namespace): namespace[\u0026#39;abstract_methods\u0026#39;] = Interface._get_abstract_methods(namespace) namespace[\u0026#39;all_methods\u0026#39;] = Interface._get_all_methods(namespace) cls = super().__new__(cls, name, bases, namespace) return cls def _get_abstract_methods(namespace): ret = [] for name, val in namespace.items(): if callable(val) and getattr(val, \u0026#39;__isabstract__\u0026#39;, False): ret.append(name) return ret def _get_all_methods(namespace): ret = [] for name, val in namespace.items(): if callable(val): ret.append(name) return ret # the __calls__() function calls the __new__() and __init__() methods of the metaclass class NetworkInterface(metaclass=Interface): @abstract_func def connect(self): pass @abstract_func def transfer(self): pass # The object of this class will not be created  # because of missing abstract method class TestNetwork(NetworkInterface): def __init__(self): print(f\u0026#34;Init method initialized from {self}\u0026#34;) def connect(self): pass # def transfer(self): # pass c = TestNetwork() \u0026gt;\u0026gt;\u0026gt; TypeError: Can\u0026#39;t create abstract class TestNetwork! TestNetwork must implement abstract method transfer of class \u0026lt;class \u0026#39;__main__.NetworkInterface\u0026#39;\u0026gt;! After uncommenting the method \u0026gt;\u0026gt;\u0026gt; python3 test.py Init method initialized from \u0026lt;class \u0026#39;__main__.NetworkInterface\u0026#39;\u0026gt; Init method initialized from \u0026lt;class \u0026#39;__main__.TestNetwork\u0026#39;\u0026gt; Init method called from \u0026lt;__main__.TestNetwork object at 0x7fc5e7659350\u0026gt;   When we initialize TestNetwork, the following happens\n The interface init method is called twice. Once when creating the NetworkInterface and TestNetwork class from the metaclass blueprint. In the Interface init method, we iterate over the list of abstract methods in the parent class and make sure each one is present in the current class. If we don\u0026rsquo;t find a method in the class with the same name, we raise an exception  ","description":"","id":4,"section":"posts","tags":["python"],"title":"Abstract classes using Metaclasses","uri":"https://hashimcolombowala.com/posts/2020-12-28-python-metaclasses/"},{"content":"The Go compiler can compile the Go source go with different go specs. Fo example, if you have installed go 1.14, you can compile your source with Go spec 1.13.\nThe rules for which version of the Go spec used during compilation appear to be  If your source code is stored within the GOPATH (or you have disabled modules with GO111MODULE=off) then the version of the Go spec used to compile matches the version of the compiler you are using. ie if you have go 1.13(GOROOT points to your go installation) installed then the go spec used will be 1.13 If your source code is outside the GOPATH(or GO111MODULE=on), then the go tool will take the version from the go.mod file If no go.mod file is provided, then same as point 1 If you are in module mode(see point 2) and no version is specified in the go.mod file, then go 1.13 is used by default  The last point is interesting.\nReference: https://www.jetbrains.com/help/go/configuring-goroot-and-gopath.html\n","description":"","id":5,"section":"posts","tags":["go"],"title":"The Go Spec(compiling)","uri":"https://hashimcolombowala.com/posts/2020-06-20-the-go-spec/"},{"content":"Words of wisdom from the python interactive shell. Always good to read it once in a while and appreciate the zen of python.\nOpen the python interpretor and enter import this\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026gt;\u0026gt;\u0026gt; import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren\\\u0026#39;t special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you\\\u0026#39;re Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it\\\u0026#39;s a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let\\\u0026#39;s do more of those!   ","description":"","id":6,"section":"posts","tags":null,"title":"The Zen of Python","uri":"https://hashimcolombowala.com/posts/2020-04-17-zen-of-python/"},{"content":"A polyglot and pragrammatic programmer currently working in the observability (o11y) space. I have a background in systems engineering and love building tools for automation of cloud native architectures.\nOutside of tech, I enjoy going on long hikes and bikes with the wife, follow all football related things with a hyperfocus on LFC and its manager Jurgen Klopp \u0026ldquo;The normal one\u0026rdquo;.\nI may write a blog about this someday. I take a lot of inspiration in life from sports especially its lessons on winning and losing.\n","description":"","id":7,"section":"","tags":null,"title":"","uri":"https://hashimcolombowala.com/about/"}]