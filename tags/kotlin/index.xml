<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>Kotlin on Home</title><link>https://hashimcolombowala.com/tags/kotlin/</link><description>Recent content in Kotlin on Home</description><generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>hashim@hey.com (Hashim Colombowala)</managingEditor><webMaster>hashim@hey.com (Hashim Colombowala)</webMaster><copyright>Â©2024, All Rights Reserved</copyright><lastBuildDate>Mon, 07 Oct 2024 23:00:00 -0700</lastBuildDate><atom:link href="https://hashimcolombowala.com/tags/kotlin/index.xml" rel="self" type="application/rss+xml"/><item><title>What is flink and why should we care about it</title><link>https://hashimcolombowala.com/posts/2024-10-08-kafka-flink/</link><pubDate>Mon, 07 Oct 2024 23:00:00 -0700</pubDate><author>hashim@hey.com (Hashim Colombowala)</author><atom:modified>Mon, 07 Oct 2024 23:00:00 -0700</atom:modified><guid>https://hashimcolombowala.com/posts/2024-10-08-kafka-flink/</guid><description>&lt;h3 id="overview">Overview&lt;/h3>
&lt;p>Recently, the observability team was tasked with a latency reporting project. The key features included:&lt;/p>
&lt;ul>
&lt;li>Daily and monthly latency aggregations&lt;/li>
&lt;li>Support for various quantiles&lt;/li>
&lt;li>A reasonable data delay SLO (24 hours)&lt;/li>
&lt;/ul>
&lt;p>and more. For the purpose of this blog, we will focus on the data processing aspect. We needed a system that could read latency data from a Kafka stream, partition the data by various attributes such as endpoints, and precompute hourly, daily, and weekly quantiles (e.g., p50, p99).&lt;/p></description><dc:creator>Hashim Colombowala</dc:creator><category>flink</category><category>kotlin</category></item></channel></rss>