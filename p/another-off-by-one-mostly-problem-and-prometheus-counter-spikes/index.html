<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="The Problem We have observed several Prometheus counters showing false spikes (i.e., no matching increase in logs) that could correlate with nodes experiencing kernel panics and reboots.\nWhy Do Counters Spike? In Prometheus, counters are expected to be monotonic: they can never decrease. The only time a counter timeseries can decrease is if it is reset to zero (e.g., when a container restarts).\nThe PromQL functions increase() and rate() have special logic to handle counter resets like this. If a counter has a value of 100 and the next data point is 99, it is assumed that the timeseries was first reset to 0 and then incremented 99 more times. This would cause a jump of 99 in most graphs.\n"><title>Another Off-by-One (Mostly) Problem and Prometheus Counter Spikes</title>
<link rel=canonical href=https://hashimcolombowala.com/p/another-off-by-one-mostly-problem-and-prometheus-counter-spikes/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="Another Off-by-One (Mostly) Problem and Prometheus Counter Spikes"><meta property='og:description' content="The Problem We have observed several Prometheus counters showing false spikes (i.e., no matching increase in logs) that could correlate with nodes experiencing kernel panics and reboots.\nWhy Do Counters Spike? In Prometheus, counters are expected to be monotonic: they can never decrease. The only time a counter timeseries can decrease is if it is reset to zero (e.g., when a container restarts).\nThe PromQL functions increase() and rate() have special logic to handle counter resets like this. If a counter has a value of 100 and the next data point is 99, it is assumed that the timeseries was first reset to 0 and then incremented 99 more times. This would cause a jump of 99 in most graphs.\n"><meta property='og:url' content='https://hashimcolombowala.com/p/another-off-by-one-mostly-problem-and-prometheus-counter-spikes/'><meta property='og:site_name' content='Hashim Colombowala'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='o11y'><meta property='article:tag' content='metrics'><meta property='article:published_time' content='2024-10-09T21:00:00-07:00'><meta property='article:modified_time' content='2024-10-09T21:00:00-07:00'><meta name=twitter:title content="Another Off-by-One (Mostly) Problem and Prometheus Counter Spikes"><meta name=twitter:description content="The Problem We have observed several Prometheus counters showing false spikes (i.e., no matching increase in logs) that could correlate with nodes experiencing kernel panics and reboots.\nWhy Do Counters Spike? In Prometheus, counters are expected to be monotonic: they can never decrease. The only time a counter timeseries can decrease is if it is reset to zero (e.g., when a container restarts).\nThe PromQL functions increase() and rate() have special logic to handle counter resets like this. If a counter has a value of 100 and the next data point is 99, it is assumed that the timeseries was first reset to 0 and then incremented 99 more times. This would cause a jump of 99 in most graphs.\n"><link rel="shortcut icon" href=/favicon.png><script async src="https://www.googletagmanager.com/gtag/js?id=G-QYCXB9X4HB"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QYCXB9X4HB")}</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu17444537569875534604.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>üç•</span></figure><div class=site-meta><h1 class=site-name><a href=/>Hashim Colombowala</a></h1><h2 class=site-description>Software Engineer with experience working on Observability systems, K8s, Streaming/Batch Infrastructure and more at scale</h2></div></header><ol class=menu-social><li><a href=https://github.com/hash167 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://linkedin.com/in/hashimcolombowala target=_blank title=LinkedIn rel=me><svg class="icon icon-tabler icon-tabler-brand-linkedin" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="4" y="4" width="16" height="16" rx="2"/><line x1="8" y1="11" x2="8" y2="16"/><line x1="8" y1="8" x2="8" y2="8.01"/><line x1="12" y1="16" x2="12" y2="11"/><path d="M16 16v-3a2 2 0 00-4 0"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>üñãÔ∏è Blogs</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>üßë‚Äçüíº About</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>üóÇÔ∏è Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>üîç Search</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><ol><li><a href=#the-problem>The Problem</a></li><li><a href=#why-do-counters-spike>Why Do Counters Spike?</a></li><li><a href=#background>Background</a></li><li><a href=#how-are-reboots-causing-spikes>How Are Reboots Causing Spikes?</a></li><li><a href=#sequence-of-events>Sequence of Events</a></li><li><a href=#how-can-we-fix-it>How Can We Fix It?</a></li><li><a href=#conclusion>Conclusion</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/observability/ style=background-color:#2a9d8f;color:#fff>Observability</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/another-off-by-one-mostly-problem-and-prometheus-counter-spikes/>Another Off-by-One (Mostly) Problem and Prometheus Counter Spikes</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Oct 09, 2024</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>4 minute read</time></div></footer></div></header><section class=article-content><h3 id=the-problem>The Problem</h3><p>We have observed several Prometheus counters showing false spikes (i.e., no matching increase in logs) that could correlate with nodes experiencing kernel panics and reboots.</p><h3 id=why-do-counters-spike>Why Do Counters Spike?</h3><p>In Prometheus, counters are expected to be monotonic: they can never decrease. The only time a counter timeseries can decrease is if it is reset to zero (e.g., when a container restarts).</p><p>The PromQL functions <code>increase()</code> and <code>rate()</code> have special logic to handle counter resets like this. If a counter has a value of 100 and the next data point is 99, it is assumed that the timeseries was first reset to 0 and then incremented 99 more times. This would cause a jump of 99 in most graphs.</p><p><img src=/p/another-off-by-one-mostly-problem-and-prometheus-counter-spikes/graph.png width=1492 height=513 srcset="/p/another-off-by-one-mostly-problem-and-prometheus-counter-spikes/graph_hu10347298088471375106.png 480w, /p/another-off-by-one-mostly-problem-and-prometheus-counter-spikes/graph_hu2622312036944885573.png 1024w" loading=lazy alt=Graph class=gallery-image data-flex-grow=290 data-flex-basis=698px></p><h3 id=background>Background</h3><ul><li>Our Python app is running on a Gunicorn server with multiple workers. This means multiple Python processes are serving requests because Python&rsquo;s threading is restricted by the Global Interpreter Lock (GIL). Using multiprocessing is a good workaround.</li><li>The app is running on a pod on a Kubernetes node.</li><li>This app is instrumented with the Prometheus Python client in multiprocessing mode because each worker process runs independently and maintains separate metrics. Multiprocessing mode aggregates these metrics across all workers, ensuring that Prometheus scrapes produce accurate, unified data across the entire application, reflecting all requests handled by all workers.</li><li>In multiprocessing mode, each process writes its metrics to a separate <a class=link href=https://github.com/prometheus/client_python/blob/v0.12.0/prometheus_client/mmap_dict.py#L61-L69 target=_blank rel=noopener>set of mmapped files</a>. On scrape, the exporter web server reads all of these files and merges them (i.e., counters from process A and B are summed). In our Kubernetes setup, these files are stored in <code>/tmp</code>, which is mounted as a Kubernetes <code>emptyDir</code> volume in most of our workloads.</li></ul><h3 id=how-are-reboots-causing-spikes>How Are Reboots Causing Spikes?</h3><p><a class=link href=https://kubernetes.io/docs/concepts/storage/volumes/#emptydir target=_blank rel=noopener>It turns out the <code>emptyDir</code> mounted to <code>/tmp</code> persists across container crashes</a>.</p><p>We were able to exec into a pod that experienced a node reboot and confirmed that the filesystem timestamps in the metric files predated the node reboot by several days.</p><p><img src=/p/another-off-by-one-mostly-problem-and-prometheus-counter-spikes/shell.png width=1600 height=1303 srcset="/p/another-off-by-one-mostly-problem-and-prometheus-counter-spikes/shell_hu13800648201417889505.png 480w, /p/another-off-by-one-mostly-problem-and-prometheus-counter-spikes/shell_hu6015823213156503612.png 1024w" loading=lazy alt=Shell class=gallery-image data-flex-grow=122 data-flex-basis=294px></p><p><strong>This means that after a reboot, pods are coming back with their old counter values</strong>. This would normally be fine as long as the node is not down for too long‚Äîthe counter would just resume at the previous value and see no reset, as long as it hasn&rsquo;t fallen out of the backend aggregator&rsquo;s buffer (which has a 10-minute window in our setup).</p><p>In the backend, we drilled into the raw data points for the counter during one of the spikes and noticed it was incrementing and then decrementing by exactly one:</p><div class=table-wrapper><table><thead><tr><th style=text-align:left>TIMESTAMP</th><th style=text-align:left>VALUE</th></tr></thead><tbody><tr><td style=text-align:left>2024-09-23T05:05:05.37-04:00</td><td style=text-align:left>72929</td></tr><tr><td style=text-align:left>2024-09-23T05:05:35.37-04:00</td><td style=text-align:left>72929</td></tr><tr><td style=text-align:left>2024-09-23T05:06:05.37-04:00</td><td style=text-align:left>72930</td></tr><tr><td style=text-align:left>2024-09-23T05:06:35.371-04:00</td><td style=text-align:left>72930</td></tr><tr><td style=text-align:left>2024-09-23T05:07:05.371-04:00</td><td style=text-align:left>72932</td></tr><tr><td style=text-align:left>2024-09-23T05:07:35.37-04:00</td><td style=text-align:left>72932</td></tr><tr><td style=text-align:left>2024-09-23T05:08:05.37-04:00</td><td style=text-align:left>72933</td></tr><tr><td style=text-align:left>2024-09-23T05:10:59.487-04:00</td><td style=text-align:left>72932 <code>(decrease in counter)</code></td></tr><tr><td style=text-align:left>2024-09-23T05:11:29.496-04:00</td><td style=text-align:left>72932</td></tr><tr><td style=text-align:left>2024-09-23T05:11:59.5-04:00</td><td style=text-align:left>72932</td></tr><tr><td style=text-align:left>2024-09-23T05:12:29.489-04:00</td><td style=text-align:left>72932</td></tr></tbody></table></div><h3 id=sequence-of-events>Sequence of Events</h3><ol><li>The application process increments a counter from <em>n</em> to <em>n+1</em> and writes the value to the mmapped file. This writes to the Linux kernel&rsquo;s page cache (and is not immediately flushed to disk).</li><li>A scrape occurs. The multiprocess exporter opens and reads all files. The kernel sees some of the files are already in the page cache and skips reading them from disk. The scrape exports the counter as <em>n+1</em>.</li><li>A kernel panic happens before the page cache is flushed to disk. The counter increment is lost.</li><li>The node encounters a kernel panic and reboots. Since the shutdown was not graceful, pods remain assigned to the node, so after startup containers are restarted with the same pod names, etc. Since the pod name is the same, the <code>emptyDir</code> volume is reused, and the pod keeps the last counter value that was flushed to disk (<em>n</em>).</li><li>A scrape occurs, and we export the counter with a value of <em>n</em>. Prometheus queries run <code>increase([..., n+1, n])</code>, which is interpreted as an increase of <em>n</em>, causing a spike.</li></ol><p>However, we have not attempted to reproduce this behavior to confirm this theory. Since this depends on the timing of the kernel writing the dirty page to disk and the kernel panic, it also makes sense that we would not see this behavior consistently with node restarts.</p><h3 id=how-can-we-fix-it>How Can We Fix It?</h3><p>While a fix for the node reboot issue has been identified, we can be more robust here. The simplest solution is to clear out the metric files in <code>/tmp</code> on startup. Prometheus is designed for this‚Äîcounter resets are normal.</p><ol><li>We could set the Prometheus multiproc directory to a memory-backed <code>emptyDir</code> volume (<code>emptyDir.medium: Memory</code>). This would naturally be cleared on node restart. This would make writes count against container memory instead.</li><li>We could add an init container that runs <code>rm $PROMETHEUS_MULTIPROC_DIR/*.db</code> on startup. This might impact pod start time slightly but is the simplest solution.</li><li>We could make the application delete <code>$PROMETHEUS_MULTIPROC_DIR/*.db</code> on startup.</li></ol><h3 id=conclusion>Conclusion</h3><p>So here we have it. An off-by-one (decrement to the count) can lead to an increment of 99. Who would have thought.</p></section><footer class=article-footer><section class=article-tags><a href=/tags/o11y/>O11y</a>
<a href=/tags/metrics/>Metrics</a></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/how-to-use-proper-resolution-windows-in-promql-to-catch-short-spikes/><div class=article-details><h2 class=article-title>How to Use Proper Resolution Windows in PromQL to Catch Short Spikes</h2></div></a></article><article><a href=/p/tradeoffs/><div class=article-details><h2 class=article-title>Trade Offs made in o11y systems for high volume traffic</h2></div></a></article><article><a href=/p/learning-generics-by-extending-the-prometheus-python-client/><div class=article-details><h2 class=article-title>Learning Generics by extending the prometheus python client</h2></div></a></article><article><a href=/p/designing-a-metrics-system-notes/><div class=article-details><h2 class=article-title>Designing a metrics system notes</h2></div></a></article><article><a href=/p/delta/><div class=article-details><h2 class=article-title>Delta vs. Cumulative Metrics: Key Differences and System Preferences</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2018 -
2025 Hashim Colombowala</section><section class=powerby>End<br>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.29.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelector("footer.site-footer");e&&e.remove()})</script></body></html>