<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2020-04-07T19:48:52-07:00</updated><id>/feed.xml</id><title type="html">Hashim Colombowala</title><subtitle>Learning to make cloud tools with python. Hoping to write short technical blogs.</subtitle><entry><title type="html">Designing Data Intensive Applications</title><link href="/book/2020/04/07/designing-data-intensive-applications.html" rel="alternate" type="text/html" title="Designing Data Intensive Applications" /><published>2020-04-07T18:54:00-07:00</published><updated>2020-04-07T18:54:00-07:00</updated><id>/book/2020/04/07/designing-data-intensive-applications</id><content type="html" xml:base="/book/2020/04/07/designing-data-intensive-applications.html">&lt;p&gt;Updating as I read the book&lt;/p&gt;

&lt;h2 id=&quot;chapter-1---reliable-scalable-and-maintainable-applications&quot;&gt;Chapter 1 - Reliable, Scalable and Maintainable applications&lt;/h2&gt;

&lt;h3 id=&quot;latency-and-response-time&quot;&gt;Latency and Response time&lt;/h3&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;response time&lt;/code&gt; is what the client sees which includes service time, network delays and queueing delays&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Latency&lt;/code&gt; is how long the request is waiting to be serviced.&lt;/p&gt;

&lt;h3 id=&quot;p95-p99-and-p999-percentile-of-requests&quot;&gt;p95, p99 and p999 percentile of requests&lt;/h3&gt;

&lt;p&gt;Customers with slow latency are the ones most likely to have more data to compute. Thus its important to look at these outliers and not just the average customer. In Amazon’s case, an outlier could mean that a customer has more orders in his shopping cart.&lt;/p&gt;

&lt;p&gt;High percentiles of response times are also known as tail latencies&lt;/p&gt;

&lt;p&gt;An apm like New Relic can give you these metrics.&lt;/p&gt;</content><author><name></name></author><summary type="html">Updating as I read the book</summary></entry><entry><title type="html">The Pragmatic Programmer 2020</title><link href="/book/2020/04/07/pragmatic-programmer-2020.html" rel="alternate" type="text/html" title="The Pragmatic Programmer 2020" /><published>2020-04-07T18:54:00-07:00</published><updated>2020-04-07T18:54:00-07:00</updated><id>/book/2020/04/07/pragmatic-programmer-2020</id><content type="html" xml:base="/book/2020/04/07/pragmatic-programmer-2020.html">&lt;p&gt;Updating as I read the book&lt;/p&gt;

&lt;h2 id=&quot;the-cat-ate-my-source-code&quot;&gt;The Cat ate my source code&lt;/h2&gt;

&lt;p&gt;Provide solutions and not excuses. In the book, the cat while playing with a laser pointer ate the source code and owner uses that as an excuse. My key takeaway was that its okay to make mistakes, but always have options.&lt;/p&gt;

&lt;h2 id=&quot;good-enough-software&quot;&gt;Good-enough software&lt;/h2&gt;

&lt;p&gt;Good enough software doesn’t mean its okay to build sloppy code. Codebase that is simple, has automated testing and deployment, meets security and privacy standards and most importantly satisfies core user requirements. The additional bells and whistles can be added later. For eg. Give the user a &lt;code class=&quot;highlighter-rouge&quot;&gt;not implemented&lt;/code&gt; message.&lt;/p&gt;

&lt;p&gt;Building software is all about trade-offs. Speed over perfection maybe a better solution&lt;/p&gt;</content><author><name></name></author><summary type="html">Updating as I read the book</summary></entry><entry><title type="html">Python decorator common use cases</title><link href="/python/decorator/2020/04/04/python-decorator-use-cases.html" rel="alternate" type="text/html" title="Python decorator common use cases" /><published>2020-04-04T15:54:35-07:00</published><updated>2020-04-04T15:54:35-07:00</updated><id>/python/decorator/2020/04/04/python-decorator-use-cases</id><content type="html" xml:base="/python/decorator/2020/04/04/python-decorator-use-cases.html">&lt;ul&gt;
  &lt;li&gt;Timing functions. Almost always the first example on StackOverflow. (You can always use a Context Manager for these too, writing them is a good way to learn those and their &lt;code class=&quot;highlighter-rouge&quot;&gt;__enter__&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;__exit__&lt;/code&gt; dunders.)&lt;/li&gt;
  &lt;li&gt;Retrying functions. Bonus points for having longer times between tries per try.&lt;/li&gt;
  &lt;li&gt;Setting a maximum time for a function to finish executing, if the function is amenable to it (e.g. it runs in a loop)&lt;/li&gt;
  &lt;li&gt;Logging functions. There are tons of different types of these (and some PyPI packages that are based on this), because there are tons of different use cases for logging. They generally require a decorator factory or class, because they require parameters (such as the logger instance).&lt;/li&gt;
  &lt;li&gt;Simple debugging, sending a function’s inputs and outputs to a log or just stdout
Validating function inputs. Python is EAFP rather than LBYL, but it’s still useful to validate inputs sometimes depending on use case. I’ve written classes that use the same decorator with a bunch of different methods. It’s also handy to CHANGE inputs if they’re in the wrong format, e.g. if the user forgets to start a url with &lt;code class=&quot;highlighter-rouge&quot;&gt;http://&lt;/code&gt;, you can add it.&lt;/li&gt;
  &lt;li&gt;Validating function outputs, for example setting a max/min.&lt;/li&gt;
  &lt;li&gt;Waiting/rate-limiting. Don’t want that web service to ban you for pinging them too frequently!&lt;/li&gt;
  &lt;li&gt;Caching/memoization. If you’ve got an pure/idempotent (i.e. a functional programming pagradigm functions) that’s also expensive (big O/long running time) that you run several times, sometimes with the same inputs, why not cache the results so you don’t have to recalculate from scratch? Eg: &lt;code class=&quot;highlighter-rouge&quot;&gt;functools.lru_cache&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Gracefully handling database transactions, e.g. rolling back if there’s an Exception (although many DB-API packages come with their own ways to set this up)&lt;/li&gt;
  &lt;li&gt;Synchronization, i.e. acquiring and releasing locks in multithreading/multiprocessing applications&lt;/li&gt;
  &lt;li&gt;Authentication (this is what some web framework decorators do, i.e. make sure a user is logged in before they are allowed to do some task/access some resource)&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Timing functions. Almost always the first example on StackOverflow. (You can always use a Context Manager for these too, writing them is a good way to learn those and their __enter__ and __exit__ dunders.) Retrying functions. Bonus points for having longer times between tries per try. Setting a maximum time for a function to finish executing, if the function is amenable to it (e.g. it runs in a loop) Logging functions. There are tons of different types of these (and some PyPI packages that are based on this), because there are tons of different use cases for logging. They generally require a decorator factory or class, because they require parameters (such as the logger instance). Simple debugging, sending a function’s inputs and outputs to a log or just stdout Validating function inputs. Python is EAFP rather than LBYL, but it’s still useful to validate inputs sometimes depending on use case. I’ve written classes that use the same decorator with a bunch of different methods. It’s also handy to CHANGE inputs if they’re in the wrong format, e.g. if the user forgets to start a url with http://, you can add it. Validating function outputs, for example setting a max/min. Waiting/rate-limiting. Don’t want that web service to ban you for pinging them too frequently! Caching/memoization. If you’ve got an pure/idempotent (i.e. a functional programming pagradigm functions) that’s also expensive (big O/long running time) that you run several times, sometimes with the same inputs, why not cache the results so you don’t have to recalculate from scratch? Eg: functools.lru_cache. Gracefully handling database transactions, e.g. rolling back if there’s an Exception (although many DB-API packages come with their own ways to set this up) Synchronization, i.e. acquiring and releasing locks in multithreading/multiprocessing applications Authentication (this is what some web framework decorators do, i.e. make sure a user is logged in before they are allowed to do some task/access some resource)</summary></entry></feed>